{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/els285/Aachen_Intro2NN/blob/main/Exercises/3_Regression_Penguins_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpEdTntxijS0"
      },
      "source": [
        "# Regression in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeUhSP7vijS1"
      },
      "source": [
        "Repeating the procedure in PyTorch will be instructive for building neural networks in PyTorch later"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ar80QBLDijS2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq2q1IZDjI8g"
      },
      "source": [
        "## Loading data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O penguins_downloaded.csv \"https://cernbox.cern.ch/s/wh34GhKCOv0Umh7/download\"\n",
        "print(\"Download complete\")"
      ],
      "metadata": {
        "id": "JsjhqFDQjd2D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO4mmzhjijS2"
      },
      "source": [
        "Load the penguin dataset (a CSV file) using the `pandas` module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kOBvrUyijS2"
      },
      "outputs": [],
      "source": [
        "input_penguins_df = pd.read_csv(\"penguins_downloaded.csv\")\n",
        "penguins_df = input_penguins_df.dropna(inplace=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICSwTjoXijS3"
      },
      "source": [
        "For PyTorch, we need to load the data into tensors, luckily we're familiar with these already. They need to be columns hence the reshaping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPJsQ1hxijS3"
      },
      "outputs": [],
      "source": [
        "input_data = torch.tensor(penguins_df[\"flipper_length_mm\"].values, dtype=torch.float32).reshape(-1,1)\n",
        "target     = torch.tensor(penguins_df[\"body_mass_g\"].values,       dtype=torch.float32).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nh2uns_4ijS3"
      },
      "source": [
        "Our model here is a \"linear\" layer which for the simple linear regression case, will map a single value $X_i$ to a single value $y_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYCpbrqXijS4"
      },
      "outputs": [],
      "source": [
        "model = nn.Linear(1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHsbHkDEijS4"
      },
      "source": [
        "We can examine the model through the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE6oQ14cijS4"
      },
      "outputs": [],
      "source": [
        "print(model)\n",
        "print(list(model.parameters()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yudk9o94ijS4"
      },
      "source": [
        "It shows we've defined a Linear model with one input, one output, and biases turned on (which is just the y-intercept for simple linear regression). The model parameters are the things which will alter as we train - just now they're set to random values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIRJsm7QjI8j"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AssanyFsijS5"
      },
      "source": [
        "In the sklearn case, an analytic solution for ordinary least squares was implicitly used to solve the regression problem.\n",
        "\n",
        "In PyTorch, the same problem is solved iteratively by minimising some loss function and updating our two model paramters. We will use MSELoss which we saw in the lecture slides: it is a very common choice for regression problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JiwM8gfijS5"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.MSELoss()\n",
        "optimizer = optim.Rprop(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K5XnWxwijS5"
      },
      "source": [
        "Now the iteration itself, a `for` loop which:\n",
        "* Makes a prediction based on the current model\n",
        "* Computes the loss ~ the difference between the prediction and the true value\n",
        "* Updates the model\n",
        "\n",
        "This cell is slightly more verbose, so make sure you understand what each line is doing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGivz-2EijS5"
      },
      "outputs": [],
      "source": [
        "# keep track of the loss every epoch. This is only for visualisation\n",
        "losses = []\n",
        "\n",
        "N_epochs = 1000\n",
        "\n",
        "for epoch in range(N_epochs):\n",
        "    # tell the optimizer to begin an optimization step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # use the model as a prediction function: features → prediction\n",
        "    predictions = model(input_data)\n",
        "\n",
        "    # compute the loss (χ²) between these predictions and the intended targets\n",
        "    loss = loss_function(predictions, target)\n",
        "\n",
        "    # tell the loss function and optimizer to end an optimization step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{N_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUSFW6LEijS5"
      },
      "source": [
        "# Task 1\n",
        "* Try with a small number of epochs e.g. 30 and see what the loss curve looks like: has the model converged?\n",
        "* Reset the model parameters and see how many it takes for the model to converge. Beware of local minima!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdYRi036ijS5"
      },
      "source": [
        "We've printed the loss every 10 epochs to keep track that it is decreasing as we want.\n",
        "This is good practice for training ML models, rather than just waiting until all epochs have run and then examining the result.\n",
        "There are also many highly advanced tools for monitoring training: wandb.ai and TensorBoard are a couple of examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmxDD2BRijS5"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curve(losses):\n",
        "    plt.plot(losses)\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.yscale('log')\n",
        "    plt.title('Loss Curve')\n",
        "    plt.show()\n",
        "\n",
        "plot_loss_curve(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlztysllijS5"
      },
      "outputs": [],
      "source": [
        "# USE THIS TO RESET THE MODEL PARAMETERS!!!\n",
        "model.reset_parameters()\n",
        "optimizer = optim.Rprop(model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gL7XxL3ijS6"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fwd-z0RUijS6"
      },
      "source": [
        "Evaluating the model on the input data is as simple as a passing it as an argument. This returns a tensor with the derivates attached, so we have to detach these and map back to numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GJ6uCsaijS6"
      },
      "outputs": [],
      "source": [
        "y_out = model(input_data)\n",
        "y_pred = y_out.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNz-yDjDijS6"
      },
      "outputs": [],
      "source": [
        "# Plot the original data and the linear regression line\n",
        "plt.scatter(input_data, target, color='blue', label='Data Points')\n",
        "plt.plot(input_data, y_pred, color='red', label='Linear Regression Line')\n",
        "plt.xlabel('Input')\n",
        "plt.ylabel('Target')\n",
        "plt.title('Linear Regression Example')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iye_FyzgijS6"
      },
      "source": [
        "We can use the regression performance metrics from before to evaluate the performance of the model. Build a function which computes the R-squared score from it's definition:\n",
        "$ R^2 = 1 - \\frac{\\sum (y_{\\text{true}} - y_{\\text{pred}})^2}{\\sum (y_{\\text{true}} - \\bar{y_{\\text{true}}})^2}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnbFtPNxjI8m"
      },
      "outputs": [],
      "source": [
        "# @title Solution to coefficient of determination {\"display-mode\":\"form\"}\n",
        "\n",
        "# R-squared metric\n",
        "def r_squared(y_true, y_pred):\n",
        "    ss_res = torch.sum((y_true - y_pred) ** 2)\n",
        "    ss_tot = torch.sum((y_true - torch.mean(y_true)) ** 2)\n",
        "    return 1 - (ss_res / ss_tot)\n",
        "\n",
        "r_squared_value = r_squared(target, y_pred)\n",
        "print(r_squared_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q54zJiRgijS6"
      },
      "source": [
        "# Task 2: Multilinear Regression in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtK-7jv3ijS6"
      },
      "source": [
        "Extend to multilinear regression. You will need to adapt the `Linear` model to take more than single inputs. How does the $R^2$ compare?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "9X_Z62Fnkam9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWBhx_DWijS6"
      },
      "outputs": [],
      "source": [
        "input_data2D = torch.tensor(penguins_df[[\"flipper_length_mm\" , \"bill_depth_mm\"]].values, dtype=torch.float32)\n",
        "target     = torch.tensor(penguins_df[\"body_mass_g\"].values,       dtype=torch.float32).reshape(-1,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzPPlhkiijS6"
      },
      "outputs": [],
      "source": [
        "model2 = nn.Linear(2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wc-6oMJEijS6"
      },
      "outputs": [],
      "source": [
        "loss_function = nn.MSELoss()\n",
        "optimizer = optim.Rprop(model2.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLz1V-R0ijS6"
      },
      "outputs": [],
      "source": [
        "# keep track of the loss every epoch. This is only for visualisation\n",
        "losses = []\n",
        "\n",
        "N_epochs = 3000\n",
        "\n",
        "for epoch in range(N_epochs):\n",
        "    # tell the optimizer to begin an optimization step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # use the model as a prediction function: features → prediction\n",
        "    predictions = model2(input_data2D)\n",
        "\n",
        "    # compute the loss (χ²) between these predictions and the intended targets\n",
        "    loss = loss_function(predictions, target)\n",
        "\n",
        "    # tell the loss function and optimizer to end an optimization step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{N_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa9hltguijS7"
      },
      "outputs": [],
      "source": [
        "plot_loss_curve(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_HQ3iSzjI8n"
      },
      "outputs": [],
      "source": [
        "y_out2 = model2(input_data2D)\n",
        "y_pred2 = y_out2.detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hjtlf3UjI8n"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVnUBfkIjI8u"
      },
      "source": [
        "Implementing the neural network part is trivial. We simply replace our `model` with one defined by `nn.Sequential`, as shown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl4y1pNYjI8u"
      },
      "outputs": [],
      "source": [
        "model_DNN = nn.Sequential(nn.Linear(1, 50),\n",
        "                          nn.ReLU(),\n",
        "                          nn.Linear(50, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a multilinear regression model, which takes in whatever inputs you wish, and regress another continuous value. Use the `nn.Sequential` defined above, or something similar.\n",
        "\n",
        "What other metrics can we use to define our regression model performance? Refer to [Scikit-Learn regression metrics](https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics)"
      ],
      "metadata": {
        "id": "wjcqkHvzk6Sh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Solution"
      ],
      "metadata": {
        "id": "kEzmlsaflQQ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oq6IeDzvjI8u"
      },
      "outputs": [],
      "source": [
        "# Optimiser and loss function\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = optim.Rprop(model_DNN.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STh2ncgNjI8u"
      },
      "outputs": [],
      "source": [
        "# Trainging loop\n",
        "# keep track of the loss every epoch. This is only for visualisation\n",
        "losses = []\n",
        "N_epochs = 3000\n",
        "for epoch in range(N_epochs):\n",
        "    # tell the optimizer to begin an optimization step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # use the model as a prediction function: features → prediction\n",
        "    predictions = model_DNN(input_data)\n",
        "\n",
        "    # compute the loss (χ²) between these predictions and the intended targets\n",
        "    loss = loss_function(predictions, target)\n",
        "\n",
        "    # tell the loss function and optimizer to end an optimization step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{N_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnCKnmuZjI8u"
      },
      "outputs": [],
      "source": [
        "plot_loss_curve(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3me7NRkjI8u"
      },
      "outputs": [],
      "source": [
        "r_squared_value = r_squared(target, y_pred)\n",
        "print(r_squared_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiKhkiehjI8u"
      },
      "outputs": [],
      "source": [
        "input_data/input_data.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLgn3MmEjI8u"
      },
      "outputs": [],
      "source": [
        "# Perform all this again with normalized data\n",
        "input_data_normalised = (input_data - input_data.mean())/ input_data.std()\n",
        "target_normalised = (target - target.mean())/ target.std()\n",
        "# model_cheese = nn.Linear(1, 1)\n",
        "model_DNN_norm = nn.Sequential(nn.Linear(1, 50),\n",
        "                              nn.ReLU(),\n",
        "                              nn.Linear(50, 1))\n",
        "\n",
        "\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = optim.Rprop(model_DNN_norm.parameters())\n",
        "# keep track of the loss every epoch. This is only for visualisation\n",
        "losses = []\n",
        "N_epochs = 200\n",
        "for epoch in range(N_epochs):\n",
        "    # tell the optimizer to begin an optimization step\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # use the model as a prediction function: features → prediction\n",
        "    predictions = model_DNN_norm(input_data_normalised)\n",
        "\n",
        "    # compute the loss (χ²) between these predictions and the intended targets\n",
        "    loss = loss_function(predictions, target_normalised)\n",
        "\n",
        "    # tell the loss function and optimizer to end an optimization step\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    # Print the loss every 10 epochs\n",
        "    if (epoch + 1) % 1 == 0:\n",
        "        print(f'Epoch [{epoch + 1}/{N_epochs}], Loss: {loss.item():.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3tJ71FngjI8v"
      },
      "outputs": [],
      "source": [
        "plot_loss_curve(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WcExyKujI8v"
      },
      "outputs": [],
      "source": [
        "y_out = model_DNN_norm(input_data_normalised)\n",
        "y_pred = y_out.detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4LtQiEOjjI8v"
      },
      "outputs": [],
      "source": [
        "plt.plot(input_data, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHWuApCRjI8v"
      },
      "outputs": [],
      "source": [
        "# Plot the original data and the linear regression line\n",
        "plt.scatter(input_data, target, color='blue', label='Data Points')\n",
        "plt.plot(input_data, y_pred, color='red', label='Linear Regression Line')\n",
        "plt.xlabel('Input')\n",
        "plt.ylabel('Target')\n",
        "plt.title('Linear Regression Example')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5E0msf3jI8v"
      },
      "outputs": [],
      "source": [
        "target_normalised.detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmMRgQEXjI8v"
      },
      "outputs": [],
      "source": [
        "# Plot the original data and the linear regression line\n",
        "plt.scatter(input_data_normalised, target_normalised.detach().numpy(), color='blue', label='Data Points')\n",
        "plt.plot(input_data_normalised, y_pred.detach().numpy(), color='red', label='Linear Regression Line')\n",
        "plt.xlabel('Input')\n",
        "plt.ylabel('Target')\n",
        "plt.title('Linear Regression Example')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLA0MFkajI8v"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ------------------------\n",
        "# 1. Generate synthetic data\n",
        "# ------------------------\n",
        "torch.manual_seed(0)\n",
        "N = 200\n",
        "X = torch.linspace(-3, 3, N).unsqueeze(1)         # shape (N, 1)\n",
        "y_true = torch.sin(X) + 0.1 * torch.randn_like(X)  # regression target\n",
        "\n",
        "# ------------------------\n",
        "# 2. Normalize input manually\n",
        "# ------------------------\n",
        "x_mean = X.mean(0, keepdim=True)\n",
        "x_std = X.std(0, keepdim=True)\n",
        "X_norm = (X - x_mean) / x_std\n",
        "\n",
        "# ------------------------\n",
        "# 3. Define model\n",
        "# ------------------------\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(1, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)\n",
        ")\n",
        "\n",
        "# ------------------------\n",
        "# 4. Train the model\n",
        "# ------------------------\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(500):\n",
        "    optimizer.zero_grad()\n",
        "    y_pred = model(X_norm)\n",
        "    loss = criterion(y_pred, y_true)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# ------------------------\n",
        "# 5. Inference + Plot\n",
        "# ------------------------\n",
        "# Generate input points in original (unnormalized) space\n",
        "X_test = torch.linspace(-3, 3, 300).unsqueeze(1)\n",
        "\n",
        "# Normalize before inference\n",
        "X_test_norm = (X_test - x_mean) / x_std\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_test_pred = model(X_test_norm)\n",
        "\n",
        "# Plot prediction vs. ground truth\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(X.numpy(), y_true.numpy(), color='gray', alpha=0.4, label=\"Training Data\")\n",
        "plt.plot(X_test.numpy(), y_test_pred.numpy(), color='red', label=\"Model Prediction\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.title(\"1D Regression with Normalized Input\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}