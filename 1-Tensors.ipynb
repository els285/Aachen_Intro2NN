{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Tensors\n",
    "\n",
    "Intro PyTorch Tensor tutorial: [https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html]([https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html])\n",
    "\n",
    "In-depth PyTorch Tensor tutorial: [https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)\n",
    "\n",
    "We talk about and use tensors all the time in machine learning. Tensors are really **multidimensional arrays**\n",
    "\n",
    "You might think of a tensor like a matrix or the same thing as a tensor from mathematics (multiliner algebra, liek you would find if you have studied general relativity for example); but it's important to keep in mind that matrices and mathemaetical tensors have specific mathematical definitions and properties. Machine learning tensors are really jsut arrays..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "T = torch.tensor([[1,2,3],[4,5,6]]) # Creates a 2x3 tensor from a nested Python list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to understand the shape of a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as well as the numerical type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create tensors of specific `dtype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2 = torch.tensor([[7,8],[9,10]],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main selling point of torch tensors is that they are designed to run on GPUs, so let's understand GPU-compatibility right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device as the device that PyTorch will use\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether the tensor is stored on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(T2.is_cuda)\n",
    "print(T.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create tensors filled with specific values e.g. zeros, ones, or random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_tensor = torch.zeros(3, 3)\n",
    "one_tensor = torch.ones(2, 2)\n",
    "random_tensor = torch.rand(2, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Arithmetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors follow basic arithmetic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 4, 5])\n",
      "tensor([-1,  0,  1])\n",
      "tensor([2, 4, 6])\n",
      "tensor([0.5000, 1.0000, 1.5000])\n"
     ]
    }
   ],
   "source": [
    "# Operations with a scalar\n",
    "print(tensor1 + 2)\n",
    "print(tensor1 - 2)\n",
    "print(tensor1 * 2)\n",
    "print(tensor1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n",
      "tensor([-3, -3, -3])\n",
      "tensor([ 4, 10, 18])\n",
      "tensor([0.2500, 0.4000, 0.5000])\n",
      "tensor([  4,  25, 216])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "print(tensor1 + tensor2)\n",
    "# Subtraction\n",
    "print(tensor1 - tensor2)\n",
    "# Element-wise multiplication\n",
    "print(tensor1 * tensor2)\n",
    "# Element-wise division\n",
    "print(tensor1 / tensor2)\n",
    "# Element-wise exponentiation \n",
    "print(tensor2**tensor1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that operations are applied element-wise e.g. multiplication is not like vector or matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Very important rule**: tensor operations only work if the dimensionality of the tensors is compatible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m tensor3 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[1;32m      2\u001b[0m tensor4 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m7\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtensor3\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtensor4\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "tensor3 = torch.tensor([1, 2, 3])\n",
    "tensor4 = torch.tensor([4, 5, 6, 7])\n",
    "\n",
    "tensor3+tensor4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More advanced mathematical operations are applied element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.4142, 1.7321])\n",
      "tensor([0.0000, 0.6931, 1.0986])\n",
      "tensor([ 0.5403, -0.4161, -0.9900])\n"
     ]
    }
   ],
   "source": [
    "print(torch.sqrt(tensor1))\n",
    "print(torch.log(tensor1))\n",
    "print(torch.cos(tensor1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "Let's consider 100 projecticles fired with random initial velocities and random initial angles\n",
    "* Create a tensor called `u0` of shape Nx1 with random values between 0 and 10 \n",
    "* Create a tensor `angle` of same shape with random values between 0 and pi/2. \n",
    "* Compute the vertical component of initial velocity of each projectile ($ v_0^y = u_0 \\sin(\\theta) $)\n",
    "* Compute the vertical displacement of each projectile after one second ($ y = v_0^yt + \\frac{1}{2}gt^2$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "u0 = 10*torch.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = torch.pi/2*torch.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "vertical = u0*torch.sin(angle) - 9.8*torch.arange(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.0003e-01, -2.8219e+00, -1.3322e+01, -4.0693e+01, -7.1760e+01,\n",
       "        -1.1480e+02, -1.7350e+02, -2.3451e+02, -3.1325e+02, -3.8921e+02,\n",
       "        -4.8763e+02, -5.9129e+02, -7.0408e+02, -8.2719e+02, -9.5766e+02,\n",
       "        -1.0987e+03, -1.2512e+03, -1.4160e+03, -1.5863e+03, -1.7684e+03,\n",
       "        -1.9528e+03, -2.1571e+03, -2.3641e+03, -2.5872e+03, -2.8220e+03,\n",
       "        -3.0606e+03, -3.3119e+03, -3.5680e+03, -3.8337e+03, -4.1148e+03,\n",
       "        -4.4077e+03, -4.7061e+03, -5.0161e+03, -5.3313e+03, -5.6628e+03,\n",
       "        -6.0020e+03, -6.3492e+03, -6.7074e+03, -7.0687e+03, -7.4500e+03,\n",
       "        -7.8382e+03, -8.2293e+03, -8.6404e+03, -9.0600e+03, -9.4810e+03,\n",
       "        -9.9203e+03, -1.0367e+04, -1.0823e+04, -1.1286e+04, -1.1763e+04,\n",
       "        -1.2245e+04, -1.2744e+04, -1.3248e+04, -1.3760e+04, -1.4288e+04,\n",
       "        -1.4821e+04, -1.5363e+04, -1.5915e+04, -1.6483e+04, -1.7051e+04,\n",
       "        -1.7637e+04, -1.8231e+04, -1.8833e+04, -1.9445e+04, -2.0067e+04,\n",
       "        -2.0702e+04, -2.1344e+04, -2.1991e+04, -2.2657e+04, -2.3324e+04,\n",
       "        -2.4010e+04, -2.4696e+04, -2.5399e+04, -2.6112e+04, -2.6832e+04,\n",
       "        -2.7559e+04, -2.8294e+04, -2.9047e+04, -2.9806e+04, -3.0576e+04,\n",
       "        -3.1359e+04, -3.2144e+04, -3.2946e+04, -3.3749e+04, -3.4574e+04,\n",
       "        -3.5402e+04, -3.6238e+04, -3.7087e+04, -3.7940e+04, -3.8805e+04,\n",
       "        -3.9685e+04, -4.0572e+04, -4.1470e+04, -4.2378e+04, -4.3295e+04,\n",
       "        -4.4216e+04, -4.5157e+04, -4.6103e+04, -4.7053e+04, -4.8025e+04])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u0*torch.sin(angle) - 9.8*0.5*torch.arange(100)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `stack` operation combines tensors along a new dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Stack vertically (along dim=0)\n",
    "print(torch.stack((tensor1, tensor2), dim=0))\n",
    "\n",
    "# Stack horizontally (along dim=1)\n",
    "print(torch.stack((tensor1, tensor2), dim=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `concatenate` operation combines tensors along an existing dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print(torch.cat((tensor1, tensor2), dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some reshaping operations for changing the shape of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(tensor1.reshape(-1,1))\n",
    "print(tensor1.reshape(-1,1).shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Let's make some pretend Large Hadron Collider data\n",
    "\n",
    "* Create 3 tensors (size 10000x1) corresponding to the $x$, $y$ and $z$ components of 10000 different particles e.g.\n",
    "```\n",
    "px = 100*torch.randn(n_events)\n",
    "```\n",
    "* Compute a tensor for the energy using the relation $E^2 = p_x^2 + p_y^2 + p_z^2 + m^2$ where we will assume the energy to be zero.\n",
    "* Combine the four tensors into one tensor of shape (10000,4)\n",
    "* Filter the array: return a sub-array containing only particles (rows) which have $\\sqrt{p_x^2 + p_y^2} > 50$\n",
    "* Find the largest $p_z$ value in the array\n",
    "* Find the index of particles with the largest and the smallest energy\n",
    "* Normlise each column of such that the values lie between -1 and 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 4])\n",
      "tensor([[ 15.2211, -57.6250, 120.9803, 134.8650],\n",
      "        [170.4215,  82.7710, -45.4076, 194.8239],\n",
      "        [ 85.0652,  66.0822, -47.6920, 117.8027],\n",
      "        ...,\n",
      "        [-48.1688, -89.3967, -11.0948, 102.1523],\n",
      "        [102.6607,  38.2144,  79.1791, 135.1625],\n",
      "        [-29.6655, 189.6720, 117.3229, 224.9893]])\n",
      "torch.Size([8827, 4])\n",
      "tensor([[ 15.2211, -57.6250, 120.9803, 134.8650],\n",
      "        [170.4215,  82.7710, -45.4076, 194.8239],\n",
      "        [ 85.0652,  66.0822, -47.6920, 117.8027],\n",
      "        ...,\n",
      "        [-48.1688, -89.3967, -11.0948, 102.1523],\n",
      "        [102.6607,  38.2144,  79.1791, 135.1625],\n",
      "        [-29.6655, 189.6720, 117.3229, 224.9893]])\n",
      "tensor(421.6800)\n",
      "tensor(8281)\n",
      "tensor(3821)\n",
      "tensor([[ 0.1101, -0.0282,  0.2214, -0.6067],\n",
      "        [ 0.5158,  0.3045, -0.2094, -0.3288],\n",
      "        [ 0.2926,  0.2650, -0.2153, -0.6858],\n",
      "        ...,\n",
      "        [-0.0556, -0.1035, -0.1205, -0.7584],\n",
      "        [ 0.3386,  0.1989,  0.1132, -0.6054],\n",
      "        [-0.0073,  0.5579,  0.2120, -0.1890]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Number of events\n",
    "n_events = 10000\n",
    "\n",
    "# Rest mass of the particle (assumed to be 1.0 for this example)\n",
    "m = 0.0\n",
    "\n",
    "# Randomly generate 3-momentum components (px, py, pz)\n",
    "px = 100*torch.randn(n_events)  # Random px values from normal distribution\n",
    "py = 100*torch.randn(n_events)  # Random py values from normal distribution\n",
    "pz = 100*torch.randn(n_events)  # Random pz values from normal distribution\n",
    "\n",
    "# Calculate the energy E using the relativistic energy-momentum relation\n",
    "E = torch.sqrt(px**2 + py**2 + pz**2 + m**2)\n",
    "\n",
    "# Stack the 4-momentum components into a tensor of shape (n_events, 4)\n",
    "momentum_tensor = torch.stack((px, py, pz, E), dim=1)\n",
    "\n",
    "# Print out the shape of the resulting tensor\n",
    "print(momentum_tensor.shape)  # Should be (10000, 4)\n",
    "print(momentum_tensor)  # Print first few events for inspection\n",
    "\n",
    "# Apply a mask to filter out events with momentum magnitude greater than 50\n",
    "mask = torch.sqrt((momentum_tensor[:,0]**2) + (momentum_tensor[:,1]**2))>50\n",
    "filtered_momentum_tensor = momentum_tensor[mask]\n",
    "\n",
    "# Print the results\n",
    "print(filtered_momentum_tensor.shape)\n",
    "print(filtered_momentum_tensor)\n",
    "\n",
    "# Use torch.max to find the maximum value of the z-component of the momentum\n",
    "print(torch.max(filtered_momentum_tensor[:,2]))\n",
    "\n",
    "# Use torch.arg and torch.argmin to find the index of the maximum and minimum values of the energy\n",
    "print(torch.argmax(filtered_momentum_tensor[:,3]))\n",
    "print(torch.argmin(filtered_momentum_tensor[:,3]))\n",
    "\n",
    "# Normalise each column's values to lie between -1 and 1\n",
    "normalised_momentum_tensor = 2*(filtered_momentum_tensor - torch.min(filtered_momentum_tensor, dim=0).values) / (torch.max(filtered_momentum_tensor, dim=0).values - torch.min(filtered_momentum_tensor, dim=0).values) - 1\n",
    "print(normalised_momentum_tensor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
